
# ğŸ§  AI Virtual Assistant with Gesture & Eye Detection

### ğŸ‘‹ Overview

This project is an **AI-powered virtual assistant** that uses **hand gestures** and **eye detection** to interact with your system. It combines **computer vision**, **speech synthesis**, and **automation** to create a futuristic hands-free desktop control system.

The assistant uses **MediaPipe** to detect hand gestures, **OpenCV** for face and eye tracking, and **pyttsx3** for text-to-speech responses â€” turning your webcam into a smart human-computer interface.

---

## âš™ï¸ Features

âœ… **ğŸ‘ï¸ Eye Detection & Fatigue Alert**

* Detects if your eyes are closed for more than 5 seconds.
* Triggers an audio alert: *â€œAlert! Please open your eyes.â€*

âœ… **âœ‹ Hand Gesture Recognition**

* Detects your right-hand gestures using MediaPipe.
* Opens applications or websites based on your finger combinations.

âœ… **ğŸ—£ï¸ Voice Feedback System**

* Uses `pyttsx3` to speak system responses.
* Greets you on start-up and confirms every action verbally.

âœ… **ğŸŒ Smart System Integration**

* Opens web apps (YouTube, Hotstar, etc.) and system apps (Notepad, Camera, Edge) directly from hand gestures.
* Automatically terminates any previously opened process before launching a new one.

---

## ğŸ§© Gesture Control Mappings

| Gesture (Right Hand)               | Action              |
| ---------------------------------- | ------------------- |
| â˜ï¸ (Index finger up)               | Open YouTube        |
| âœŒï¸ (Index + Middle)                | Open Hotstar        |
| ğŸ¤Ÿ (Index + Middle + Ring)         | Open Camera         |
| ğŸ–– (Index + Middle + Ring + Pinky) | Open Microsoft Edge |
| ğŸ–ï¸ (All fingers up)               | Open Notepad        |

---

## ğŸ§  Tech Stack

* **Python 3.8+**
* **OpenCV** â€“ for face & eye detection
* **MediaPipe** â€“ for hand gesture recognition
* **pyttsx3** â€“ for speech synthesis
* **subprocess / webbrowser / os** â€“ for system automation

---

## ğŸ–¥ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/AI-Virtual-Assistant.git
cd AI-Virtual-Assistant
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install opencv-python mediapipe pyttsx3
```

### 3ï¸âƒ£ Run the program

```bash
python virtual_assistant.py
```

---

## âš¡ How It Works

1. The webcam feed is processed frame-by-frame using **OpenCV**.
2. **MediaPipe Hands** detects hand landmarks and identifies finger positions.
3. Specific finger patterns are mapped to apps/websites.
4. **OpenCV Haar Cascades** detect eyes â€” if closed for too long, a **fatigue alert** is triggered.
5. The **TTS engine** speaks every system action for better user interaction.

---

## ğŸ§  Future Enhancements

ğŸš€ AI voice command support using **SpeechRecognition**
ğŸ§â€â™‚ï¸ Body pose detection for full-body gesture control
ğŸ’¬ Integration with **ChatGPT API / LangChain** for intelligent Q&A
ğŸ§ Add wake-word detection (â€œHey Assistantâ€)
ğŸŒ— GUI dashboard to manage gesture mappings

---

## ğŸ§‘â€ğŸ’» Developer

**ğŸ‘¨â€ğŸ’» Developer:** **
**ğŸ”— Skills:** Computer Vision, Python Automation, Machine Learning, Cybersecurity
**ğŸ’¼ Organization:** Goklyn Private Limited, Jaipur

---

## ğŸ›¡ï¸ Disclaimer

This project is built purely for educational and research purposes. It should not be used for any form of surveillance or privacy-invasive tasks without consent.

---

## â­ Contribution

Contributions are welcome!
Fork the repo, create a feature branch, and submit a pull request.

```bash
git checkout -b feature/your-feature
git commit -m "Added a new gesture command"
git push origin feature/your-feature
```

---
